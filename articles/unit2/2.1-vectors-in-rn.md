---
layout: article
title: "Vectors in ℝⁿ"
---



_What is a vector, really?_

---

## Two Ways to Think About Vectors

The word "vector" gets used in a lot of ways. In physics, it's an arrow with magnitude and direction. In computer science, it's a list of numbers. In mathematics, it can be either — and understanding both perspectives is key to linear algebra.

### The Arrow Picture

Imagine an arrow in 2D space, starting at the origin and pointing somewhere:

<iframe src="https://ilundholm.github.io/linear_algebra_KA/widgets/vector-coordinates.html" width="100%" height="550" style="border: none; border-radius: 8px;"></iframe>

This arrow has:
- A **direction** (where it points)
- A **magnitude** (how long it is)

We can describe this arrow by the coordinates of its tip. If the tip is at $(3, 2)$, we write:

$$
\mathbf{v} = \begin{bmatrix} 3 \\ 2 \end{bmatrix}
$$

This is a **vector in ℝ²** (two-dimensional real space).

### The List Picture

Alternatively, we can just think of a vector as an ordered list of numbers:

$$
\mathbf{v} = \begin{bmatrix} 3 \\ 2 \end{bmatrix}
$$

No arrows, no geometry — just two numbers stacked vertically.

This might seem less intuitive, but it's incredibly powerful. Why? Because it generalizes. A vector in ℝ³ has three components:

$$
\mathbf{w} = \begin{bmatrix} 1 \\ -2 \\ 5 \end{bmatrix}
$$

And a vector in ℝ¹⁰⁰ has one hundred components. We can't visualize that, but we can still compute with it.

<details>
<summary><strong>Which picture should I use?</strong></summary>

Both! The arrow picture builds intuition in 2D and 3D. The list picture lets you generalize to higher dimensions and do calculations.

In this course, we'll constantly switch between them. When we want to *understand* something, we'll draw arrows. When we want to *compute* something, we'll work with lists.

</details>

---

## Vector Addition

What happens when you add two vectors?

### Geometrically: Tip-to-Tail

Place the second arrow's tail at the first arrow's tip. The sum is the arrow from the origin to the final tip.

<video src="/linear_algebra_KA/videos/VectorAdditionTipToTail.mp4" autoplay loop muted playsinline style="max-width:100%; border-radius:8px;"></video>
_Animation showing two vectors being added tip-to-tail. The parallelogram rule is also shown._

This is sometimes called the **parallelogram rule**: if you put both arrows at the origin, the sum is the diagonal of the parallelogram they form.

### Algebraically: Component-wise

Just add the corresponding components:

$$
\begin{bmatrix} 3 \\ 2 \end{bmatrix} + \begin{bmatrix} 1 \\ 4 \end{bmatrix} = \begin{bmatrix} 3+1 \\ 2+4 \end{bmatrix} = \begin{bmatrix} 4 \\ 6 \end{bmatrix}
$$

That's it. No tricks.

<iframe src="https://ilundholm.github.io/linear_algebra_KA/widgets/vector-addition.html" width="100%" height="550" style="border: none; border-radius: 8px;"></iframe>

---

**Practice Problem:** Compute the following:

$$\begin{bmatrix} 2 \\ -1 \\ 3 \end{bmatrix} + \begin{bmatrix} -1 \\ 4 \\ 2 \end{bmatrix}$$

$$\text{(A) } \begin{bmatrix} 1 \\ 3 \\ 5 \end{bmatrix} \qquad \text{(B) } \begin{bmatrix} 3 \\ -5 \\ 1 \end{bmatrix} \qquad \text{(C) } \begin{bmatrix} 1 \\ 5 \\ 3 \end{bmatrix} \qquad \text{(D) } \begin{bmatrix} -2 \\ -4 \\ 6 \end{bmatrix}$$

<details>
<summary><strong>Check your answer</strong></summary>

**(A)**

$$\begin{bmatrix} 1 \\ 3 \\ 5 \end{bmatrix}$$

$$
\begin{bmatrix} 2 \\ -1 \\ 3 \end{bmatrix} + \begin{bmatrix} -1 \\ 4 \\ 2 \end{bmatrix} = \begin{bmatrix} 2 + (-1) \\ -1 + 4 \\ 3 + 2 \end{bmatrix} = \begin{bmatrix} 1 \\ 3 \\ 5 \end{bmatrix}
$$

</details>

---

## Scalar Multiplication

A **scalar** is just a fancy word for a number (as opposed to a vector). When you multiply a vector by a scalar, you scale every component:

$$
3 \cdot \begin{bmatrix} 2 \\ -1 \end{bmatrix} = \begin{bmatrix} 3 \cdot 2 \\ 3 \cdot (-1) \end{bmatrix} = \begin{bmatrix} 6 \\ -3 \end{bmatrix}
$$

### Geometrically

Scalar multiplication changes the **length** of the vector:
- Multiply by 2: arrow gets twice as long
- Multiply by 0.5: arrow gets half as long
- Multiply by -1: arrow flips direction
- Multiply by 0: arrow collapses to a point

<video src="/linear_algebra_KA/videos/ScalarMultiplication.mp4" autoplay loop muted playsinline style="max-width:100%; border-radius:8px;"></video>
_Animation showing a vector being scaled by different values. A slider controls the scalar from -2 to 2._

The direction stays the same (or reverses if the scalar is negative), but the magnitude changes.

---

**Practice Problem:** What is the following?

$$-2 \cdot \begin{bmatrix} 3 \\ -4 \end{bmatrix}$$

$$\text{(A) } \begin{bmatrix} -6 \\ -8 \end{bmatrix} \qquad \text{(B) } \begin{bmatrix} -6 \\ 8 \end{bmatrix} \qquad \text{(C) } \begin{bmatrix} 6 \\ 8 \end{bmatrix} \qquad \text{(D) } \begin{bmatrix} 6 \\ -8 \end{bmatrix}$$

<details>
<summary><strong>Check your answer</strong></summary>

**(B)**

$$\begin{bmatrix} -6 \\ 8 \end{bmatrix}$$

$$
-2 \cdot \begin{bmatrix} 3 \\ -4 \end{bmatrix} = \begin{bmatrix} -2 \cdot 3 \\ -2 \cdot (-4) \end{bmatrix} = \begin{bmatrix} -6 \\ 8 \end{bmatrix}
$$

The negative scalar flips the direction, so both signs change.

</details>

---

## The Zero Vector

There's a special vector with all zeros:

$$
\mathbf{0} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} \quad \text{(in ℝ²)}
$$

$$
\mathbf{0} = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix} \quad \text{(in ℝ³)}
$$

This is the **zero vector**. Geometrically, it's an arrow with no length — a point at the origin.

It plays the same role for vectors that the number 0 plays for real numbers:

$$
\mathbf{v} + \mathbf{0} = \mathbf{v}
$$

Adding zero doesn't change anything.

---

## Additive Inverses

For every vector $\mathbf{v}$, there's another vector $-\mathbf{v}$ such that:

$$
\mathbf{v} + (-\mathbf{v}) = \mathbf{0}
$$

This is just the vector with all signs flipped:

$$
\text{If } \mathbf{v} = \begin{bmatrix} 3 \\ -2 \end{bmatrix}, \text{ then } -\mathbf{v} = \begin{bmatrix} -3 \\ 2 \end{bmatrix}
$$

Geometrically, $-\mathbf{v}$ points in the exact opposite direction from $\mathbf{v}$, with the same length.

---

## Properties of Vector Operations

Vector addition and scalar multiplication behave nicely. Here are the key properties (you don't need to memorize these — they're just "obvious" facts):

**For vectors $\mathbf{u}, \mathbf{v}, \mathbf{w}$ and scalars $c, d$:**

| Property | Statement |
|----------|-----------|
| Commutativity | $\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}$ |
| Associativity | $(\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})$ |
| Zero vector | $\mathbf{v} + \mathbf{0} = \mathbf{v}$ |
| Additive inverse | $\mathbf{v} + (-\mathbf{v}) = \mathbf{0}$ |
| Scalar distributivity | $c(\mathbf{u} + \mathbf{v}) = c\mathbf{u} + c\mathbf{v}$ |
| Vector distributivity | $(c + d)\mathbf{v} = c\mathbf{v} + d\mathbf{v}$ |
| Associativity of scalars | $c(d\mathbf{v}) = (cd)\mathbf{v}$ |
| Identity scalar | $1 \cdot \mathbf{v} = \mathbf{v}$ |

These properties are what make vectors form a **vector space** — a concept we'll explore more deeply later in the course.

---

## Vectors in Different Dimensions

So far, we've mostly used ℝ² (2D) and ℝ³ (3D) examples. But the ideas extend to any dimension.

A vector in ℝⁿ is an ordered list of $n$ real numbers:

$$
\mathbf{v} = \begin{bmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{bmatrix}
$$

We call $v_1$ the first **component**, $v_2$ the second component, and so on.

**Why would you ever want more than 3 dimensions?**

- **Data science:** A data point with 50 features is a vector in ℝ⁵⁰
- **Economics:** A market basket of 1000 goods is a vector in ℝ¹⁰⁰⁰
- **Machine learning:** Word embeddings often live in ℝ³⁰⁰
- **Physics:** Quantum states can be vectors in infinite-dimensional spaces

The geometry of ℝ² and ℝ³ builds intuition. The algebra of ℝⁿ lets you apply that intuition everywhere.

---

**Practice Problem:** In ℝ⁴, what is the zero vector?

- (A) $\begin{bmatrix} 0 \end{bmatrix}$
- (B) $\begin{bmatrix} 0 \\ 0 \end{bmatrix}$
- (C) $\begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}$
- (D) $\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}$

<details>
<summary><strong>Check your answer</strong></summary>

**(D) $\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}$**

The zero vector in ℝⁿ has exactly $n$ components, all equal to zero. In ℝ⁴, that's four zeros.

</details>

---

## Summary

- A **vector** is both an arrow (geometric) and a list of numbers (algebraic)
- **Vector addition:** Add component-wise; geometrically, tip-to-tail
- **Scalar multiplication:** Scale every component; geometrically, stretch or shrink (possibly flip)
- The **zero vector** $\mathbf{0}$ has all zero components
- The **additive inverse** $-\mathbf{v}$ flips all signs
- These ideas work in **any dimension** ℝⁿ

---

## What's Next?

Now that we know what vectors are and how to add and scale them, we can ask a deeper question:

Given a collection of vectors, what can you build by adding and scaling them? 

This leads us to **linear combinations** and **span** — the foundation of the column picture of linear algebra.


---

[← Previous: Applications](../unit1/1.4-applications.md) | [Back to Home](https://ilundholm.github.io/linear_algebra_KA/) | [Next: Linear Combinations and Span →](2.2-linear-combinations-and-span.md)
